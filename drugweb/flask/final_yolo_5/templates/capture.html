<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <style>
#video {
  border: 1px solid black;
  box-shadow: 2px 2px 3px black;
  width: 320px;
  height: 240px;
}

#photo {
  border: 1px solid black;
  box-shadow: 2px 2px 3px black;
  width: 320px;
  height: 240px;
}

#canvas {
  display: none;
}

.camera {
  width: 340px;
  display: inline-block;
}

.output {
  width: 340px;
  display: inline-block;
  vertical-align: top;
}

#startbutton {
  display: block;
  position: relative;
  margin-left: auto;
  margin-right: auto;
  bottom: 32px;
  background-color: rgba(0, 150, 0, 0.5);
  border: 1px solid rgba(255, 255, 255, 0.7);
  box-shadow: 0px 0px 1px 2px rgba(0, 0, 0, 0.2);
  font-size: 14px;
  font-family: "Lucida Grande", "Arial", sans-serif;
  color: rgba(255, 255, 255, 1);
}

.contentarea {
  font-size: 16px;
  font-family: "Lucida Grande", "Arial", sans-serif;
  width: 760px;
}

    </style>
</head>
<body>
    <div class="contentarea">
        <h1>MDN - navigator.mediaDevices.getUserMedia(): Still photo capture demo</h1>
        <p>
            This example demonstrates how to set up a media stream using your built-in
            webcam, fetch an image from that stream, and create a PNG using that image.
        </p>
        <div class="camera">
            <video id="video">Video stream not available.</video>
            <button id="startbutton">Take photo</button>
        </div>
        <canvas id="canvas"> </canvas>
        <div class="output">
            <img id="photo" alt="The screen capture will appear in this box." />
        </div>
        <div>
            <button id="send-btn">
                전송하기
            </button>
        </div>
        <p>
            Visit our article
            <a
            href="https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API/Taking_still_photos">
            Taking still photos with WebRTC</a
            >
            to learn more about the technologies used here.
        </p>
    </div>
    <script>
        (() => {
  // The width and height of the captured photo. We will set the
  // width to the value defined here, but the height will be
  // calculated based on the aspect ratio of the input stream.

  const width = 320; // We will scale the photo width to this
  let height = 0; // This will be computed based on the input stream

  // |streaming| indicates whether or not we're currently streaming
  // video from the camera. Obviously, we start at false.

  let streaming = false;

  // The various HTML elements we need to configure or control. These
  // will be set by the startup() function.

  let video = null;
  let canvas = null;
  let photo = null;
  let startbutton = null;
  let sendbutton = null;

  function showViewLiveResultButton() {
    if (window.self !== window.top) {
      // Ensure that if our document is in a frame, we get the user
      // to first open it in its own tab or window. Otherwise, it
      // won't be able to request permission for camera access.
      document.querySelector(".contentarea").remove();
      const button = document.createElement("button");
      button.textContent = "View liveW result of the example code above";
      document.body.append(button);
      button.addEventListener("click", () => window.open(location.href));
      return true;
    }
    return false;
  }

  function startup() {
    if (showViewLiveResultButton()) {
      return;
    }
    video = document.getElementById("video");
    canvas = document.getElementById("canvas");
    photo = document.getElementById("photo");
    startbutton = document.getElementById("startbutton");
    sendbutton = document.getElementById("send-btn");

    var constraints = { audio: false, video: { facingMode: "environment" }};
    //var constaingts2 = { audio: true, video: { }};
    navigator.mediaDevices.getUserMedia(constraints)
    //navigator.mediaDevices.getUserMedia(constraints2)
    .then((stream) => {
        video.srcObject = stream;
        video.play();
      })
      .catch((err) => {
        console.error(`An error occurred: ${err}`);
      });
    

    video.addEventListener(
      "canplay",
      (ev) => {
        if (!streaming) {
          height = video.videoHeight / (video.videoWidth / width);

          // Firefox currently has a bug where the height can't be read from
          // the video, so we will make
          if (isNaN(height)) {
            height = width / (4 / 3);
          }

          video.setAttribute("width", width);
          video.setAttribute("height", height);
          canvas.setAttribute("width", width);
          canvas.setAttribute("height", height);
          streaming = true;
        }
      },
      false,
    );

    startbutton.addEventListener(
      "click",
      (ev) => {
        takepicture();
        ev.preventDefault();
      },
      false,
    );

    sendbutton.addEventListener(
        "click",
        (ev) => {
            sendDataUrlViaForm(photo.src);
        },
        false,
    );

    clearphoto();
  }

  // Fill the photo with an indication that none has been
  // captured.

  function clearphoto() {
    const context = canvas.getContext("2d");
    context.fillStyle = "#AAA";
    context.fillRect(0, 0, canvas.width, canvas.height);

    const data = canvas.toDataURL("image/png");
    photo.setAttribute("src", data);
  }

  // Capture a photo by fetching the current contents of the video
  // and drawing it into a canvas, then converting that to a PNG
  // format data URL. By drawing it on an offscreen canvas and then
  // drawing that to the screen, we can change its size and/or apply
  // other changes before drawing it.

  function takepicture() {
    const context = canvas.getContext("2d");
    if (width && height) {
      canvas.width = width;
      canvas.height = height;
      context.drawImage(video, 0, 0, width, height);

      const data = canvas.toDataURL("image/png");
      console.log(data);
      photo.setAttribute("src", data);
    } else {
      clearphoto();
    }
  }

  function sendDataUrlViaForm(dataUrl) {
    var formData = new FormData();
    var blob = dataURLToBlob(dataUrl);
    formData.append("file", blob, "filename.png"); // "file"은 서버에서 파일을 받을 때 사용할 키 이름입니다.

    // Ajax 또는 Fetch 등을 사용하여 formData를 서버로 전송합니다.
    // 아래는 Fetch API를 사용한 예시입니다.
    fetch("/predict", {
        method: "POST",
        body: formData
    })
    .then(response => {
      // 응답 처리
    })
    .catch(error => {
      // 오류 처리
    });
}

// Data URL을 Blob 객체로 변환하는 함수
function dataURLToBlob(dataUrl) {
  var arr = dataUrl.split(",");
  var mime = arr[0].match(/:(.*?);/)[1];
  var bstr = atob(arr[1]);
  var n = bstr.length;
  var u8arr = new Uint8Array(n);
  while (n--) {
    u8arr[n] = bstr.charCodeAt(n);
  }
  return new Blob([u8arr], { type: mime });
}

  // Set up our event listener to run the startup process
  // once loading is complete.
  window.addEventListener("load", startup, false);
})();
    </script>
</body>
</html>